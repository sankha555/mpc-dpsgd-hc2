BATCH SIZE = 2000 CLIP FACTOR = 4.0 	SIGMA = 4.0
Epoch 1.1: Loss = 2.308140516281128
	Train Epoch: 1 	Loss: 2.308141 Acc@1: 0.081500 (ε = 0.11, δ = 1e-05)
Epoch 1.2: Loss = 2.289097785949707
Epoch 1.3: Loss = 2.273294687271118
Epoch 1.4: Loss = 2.258944511413574
Epoch 1.5: Loss = 2.2379937171936035
Epoch 1.6: Loss = 2.2212107181549072
Epoch 1.7: Loss = 2.1967713832855225
Epoch 1.8: Loss = 2.1715946197509766
Epoch 1.9: Loss = 2.1451358795166016
Epoch 1.10: Loss = 2.115325927734375
Epoch 1.11: Loss = 2.0745127201080322
Epoch 1.12: Loss = 2.0368292331695557
Epoch 1.13: Loss = 1.989258050918579
Epoch 1.14: Loss = 1.9487379789352417
Epoch 1.15: Loss = 1.906305193901062
Epoch 1.16: Loss = 1.8437281847000122
Epoch 1.17: Loss = 1.788203477859497
Epoch 1.18: Loss = 1.7173120975494385
Epoch 1.19: Loss = 1.6709784269332886
Epoch 1.20: Loss = 1.6071738004684448
Epoch 1.21: Loss = 1.570414662361145
Epoch 1.22: Loss = 1.517086148262024
Epoch 1.23: Loss = 1.468875765800476
Epoch 1.24: Loss = 1.4350852966308594
Epoch 1.25: Loss = 1.367783784866333
Epoch 1.26: Loss = 1.3693208694458008
Epoch 1.27: Loss = 1.333056926727295
Epoch 1.28: Loss = 1.2931548357009888
Epoch 1.29: Loss = 1.259611964225769
Epoch 1.30: Loss = 1.2395422458648682
	Test set:Loss: 1.222177 Acc@1: 0.561800 
Epoch 2.1: Loss = 1.2069011926651
	Train Epoch: 2 	Loss: 1.206901 Acc@1: 0.573500 (ε = 0.18, δ = 1e-05)
Epoch 2.2: Loss = 1.200573205947876
Epoch 2.3: Loss = 1.1540439128875732
Epoch 2.4: Loss = 1.158575177192688
Epoch 2.5: Loss = 1.1615192890167236
Epoch 2.6: Loss = 1.132308840751648
Epoch 2.7: Loss = 1.1052331924438477
Epoch 2.8: Loss = 1.1078637838363647
Epoch 2.9: Loss = 1.1022861003875732
Epoch 2.10: Loss = 1.0902559757232666
Epoch 2.11: Loss = 1.0762345790863037
Epoch 2.12: Loss = 1.0499305725097656
Epoch 2.13: Loss = 1.0450143814086914
Epoch 2.14: Loss = 1.039808988571167
Epoch 2.15: Loss = 1.0592105388641357
Epoch 2.16: Loss = 0.9936587810516357
Epoch 2.17: Loss = 0.9961139559745789
Epoch 2.18: Loss = 0.9803981184959412
Epoch 2.19: Loss = 1.0024467706680298
Epoch 2.20: Loss = 0.9601850509643555
Epoch 2.21: Loss = 0.967664361000061
Epoch 2.22: Loss = 0.9779673218727112
Epoch 2.23: Loss = 0.987500786781311
Epoch 2.24: Loss = 0.9633893370628357
Epoch 2.25: Loss = 0.9042655825614929
Epoch 2.26: Loss = 0.9766735434532166
Epoch 2.27: Loss = 0.9595146775245667
Epoch 2.28: Loss = 0.9135733842849731
Epoch 2.29: Loss = 0.9249263405799866
Epoch 2.30: Loss = 0.9166241884231567
	Test set:Loss: 0.931241 Acc@1: 0.629000 
Epoch 3.1: Loss = 0.9158809781074524
	Train Epoch: 3 	Loss: 0.915881 Acc@1: 0.643000 (ε = 0.26, δ = 1e-05)
Epoch 3.2: Loss = 0.9528024196624756
Epoch 3.3: Loss = 0.869134783744812
Epoch 3.4: Loss = 0.9168450832366943
Epoch 3.5: Loss = 0.9213703870773315
Epoch 3.6: Loss = 0.9087305068969727
Epoch 3.7: Loss = 0.8778774738311768
Epoch 3.8: Loss = 0.9003587961196899
Epoch 3.9: Loss = 0.9117751121520996
Epoch 3.10: Loss = 0.905029833316803
Epoch 3.11: Loss = 0.8997710347175598
Epoch 3.12: Loss = 0.8734937906265259
Epoch 3.13: Loss = 0.8880850076675415
Epoch 3.14: Loss = 0.8886995315551758
Epoch 3.15: Loss = 0.9062542915344238
Epoch 3.16: Loss = 0.8377358913421631
Epoch 3.17: Loss = 0.8601766228675842
Epoch 3.18: Loss = 0.8452711701393127
Epoch 3.19: Loss = 0.8814258575439453
Epoch 3.20: Loss = 0.8311589360237122
Epoch 3.21: Loss = 0.8376039862632751
Epoch 3.22: Loss = 0.8531133532524109
Epoch 3.23: Loss = 0.8810360431671143
Epoch 3.24: Loss = 0.8485724329948425
Epoch 3.25: Loss = 0.7927778959274292
Epoch 3.26: Loss = 0.8797857165336609
Epoch 3.27: Loss = 0.8596614003181458
Epoch 3.28: Loss = 0.8139132857322693
Epoch 3.29: Loss = 0.8312581181526184
Epoch 3.30: Loss = 0.8169978857040405
	Test set:Loss: 0.848601 Acc@1: 0.677300 
Epoch 4.1: Loss = 0.8335363268852234
	Train Epoch: 4 	Loss: 0.833536 Acc@1: 0.680500 (ε = 0.31, δ = 1e-05)
Epoch 4.2: Loss = 0.86905437707901
Epoch 4.3: Loss = 0.7816816568374634
Epoch 4.4: Loss = 0.8374892473220825
Epoch 4.5: Loss = 0.8327526450157166
Epoch 4.6: Loss = 0.8253946900367737
Epoch 4.7: Loss = 0.8004401922225952
Epoch 4.8: Loss = 0.8293799757957458
Epoch 4.9: Loss = 0.8308958411216736
Epoch 4.10: Loss = 0.84675133228302
Epoch 4.11: Loss = 0.8277400732040405
Epoch 4.12: Loss = 0.8107593059539795
Epoch 4.13: Loss = 0.8227806687355042
Epoch 4.14: Loss = 0.8301700353622437
Epoch 4.15: Loss = 0.8475795388221741
Epoch 4.16: Loss = 0.7833148241043091
Epoch 4.17: Loss = 0.8054510951042175
Epoch 4.18: Loss = 0.7933080196380615
Epoch 4.19: Loss = 0.8350991010665894
Epoch 4.20: Loss = 0.7801473140716553
Epoch 4.21: Loss = 0.7869108319282532
Epoch 4.22: Loss = 0.8070157766342163
Epoch 4.23: Loss = 0.84481281042099
Epoch 4.24: Loss = 0.8097719550132751
Epoch 4.25: Loss = 0.7483082413673401
Epoch 4.26: Loss = 0.8212113976478577
Epoch 4.27: Loss = 0.8122994303703308
Epoch 4.28: Loss = 0.7687498927116394
Epoch 4.29: Loss = 0.7831151485443115
Epoch 4.30: Loss = 0.7717293500900269
	Test set:Loss: 0.813490 Acc@1: 0.700800 
Epoch 5.1: Loss = 0.7948962450027466
	Train Epoch: 5 	Loss: 0.794896 Acc@1: 0.710500 (ε = 0.36, δ = 1e-05)
Epoch 5.2: Loss = 0.8387511968612671
Epoch 5.3: Loss = 0.7417530417442322
Epoch 5.4: Loss = 0.8082862496376038
Epoch 5.5: Loss = 0.7995724081993103
Epoch 5.6: Loss = 0.7862672805786133
Epoch 5.7: Loss = 0.7662662267684937
Epoch 5.8: Loss = 0.7904542684555054
Epoch 5.9: Loss = 0.7932422757148743
Epoch 5.10: Loss = 0.8053689002990723
Epoch 5.11: Loss = 0.7882006168365479
Epoch 5.12: Loss = 0.7692618370056152
Epoch 5.13: Loss = 0.7911680936813354
Epoch 5.14: Loss = 0.796052873134613
Epoch 5.15: Loss = 0.8173291683197021
Epoch 5.16: Loss = 0.7385378479957581
Epoch 5.17: Loss = 0.7723451852798462
Epoch 5.18: Loss = 0.7611253261566162
Epoch 5.19: Loss = 0.8091576099395752
Epoch 5.20: Loss = 0.743540346622467
Epoch 5.21: Loss = 0.7514330148696899
Epoch 5.22: Loss = 0.7726624608039856
Epoch 5.23: Loss = 0.8164436221122742
Epoch 5.24: Loss = 0.7687889933586121
Epoch 5.25: Loss = 0.7191206216812134
Epoch 5.26: Loss = 0.7874278426170349
Epoch 5.27: Loss = 0.7945276498794556
Epoch 5.28: Loss = 0.7379956245422363
Epoch 5.29: Loss = 0.7578399181365967
Epoch 5.30: Loss = 0.7384418845176697
	Test set:Loss: 0.791830 Acc@1: 0.721800 
Epoch 6.1: Loss = 0.7709165811538696
	Train Epoch: 6 	Loss: 0.770917 Acc@1: 0.730000 (ε = 0.41, δ = 1e-05)
Epoch 6.2: Loss = 0.817682683467865
Epoch 6.3: Loss = 0.7172756791114807
Epoch 6.4: Loss = 0.7841179966926575
Epoch 6.5: Loss = 0.7680208086967468
Epoch 6.6: Loss = 0.7581918835639954
Epoch 6.7: Loss = 0.7331076860427856
Epoch 6.8: Loss = 0.7705541849136353
Epoch 6.9: Loss = 0.7687997221946716
Epoch 6.10: Loss = 0.7836086750030518
Epoch 6.11: Loss = 0.7608727812767029
Epoch 6.12: Loss = 0.7525320053100586
Epoch 6.13: Loss = 0.7591802477836609
Epoch 6.14: Loss = 0.7868742942810059
Epoch 6.15: Loss = 0.7917540669441223
Epoch 6.16: Loss = 0.7183020114898682
Epoch 6.17: Loss = 0.758023202419281
Epoch 6.18: Loss = 0.7437246441841125
Epoch 6.19: Loss = 0.7852328419685364
Epoch 6.20: Loss = 0.7240999937057495
Epoch 6.21: Loss = 0.7296596765518188
Epoch 6.22: Loss = 0.7567168474197388
Epoch 6.23: Loss = 0.8013007044792175
Epoch 6.24: Loss = 0.7481697201728821
Epoch 6.25: Loss = 0.7100421190261841
Epoch 6.26: Loss = 0.7685767412185669
Epoch 6.27: Loss = 0.7739477753639221
Epoch 6.28: Loss = 0.7226704359054565
Epoch 6.29: Loss = 0.7431288957595825
Epoch 6.30: Loss = 0.7179067730903625
	Test set:Loss: 0.783762 Acc@1: 0.735000 
Epoch 7.1: Loss = 0.7616294026374817
	Train Epoch: 7 	Loss: 0.761629 Acc@1: 0.741000 (ε = 0.45, δ = 1e-05)
Epoch 7.2: Loss = 0.8058570027351379
Epoch 7.3: Loss = 0.7006546258926392
Epoch 7.4: Loss = 0.7791278958320618
Epoch 7.5: Loss = 0.7570270299911499
Epoch 7.6: Loss = 0.7515238523483276
Epoch 7.7: Loss = 0.722680926322937
Epoch 7.8: Loss = 0.7586843967437744
Epoch 7.9: Loss = 0.7559769749641418
Epoch 7.10: Loss = 0.7772126793861389
Epoch 7.11: Loss = 0.7488016486167908
Epoch 7.12: Loss = 0.7416233420372009
Epoch 7.13: Loss = 0.7408257722854614
Epoch 7.14: Loss = 0.7654993534088135
Epoch 7.15: Loss = 0.7791727781295776
Epoch 7.16: Loss = 0.6940874457359314
Epoch 7.17: Loss = 0.7473772764205933
Epoch 7.18: Loss = 0.7357935309410095
Epoch 7.19: Loss = 0.7778791189193726
Epoch 7.20: Loss = 0.7117177844047546
Epoch 7.21: Loss = 0.7225388288497925
Epoch 7.22: Loss = 0.7394756078720093
Epoch 7.23: Loss = 0.8016415238380432
Epoch 7.24: Loss = 0.739035964012146
Epoch 7.25: Loss = 0.6909239888191223
Epoch 7.26: Loss = 0.7446693181991577
Epoch 7.27: Loss = 0.76141357421875
Epoch 7.28: Loss = 0.7122570872306824
Epoch 7.29: Loss = 0.7363432049751282
Epoch 7.30: Loss = 0.7129830718040466
	Test set:Loss: 0.774395 Acc@1: 0.742900 
Epoch 8.1: Loss = 0.7505142688751221
	Train Epoch: 8 	Loss: 0.750514 Acc@1: 0.747500 (ε = 0.49, δ = 1e-05)
Epoch 8.2: Loss = 0.795131504535675
Epoch 8.3: Loss = 0.693498432636261
Epoch 8.4: Loss = 0.7768462300300598
Epoch 8.5: Loss = 0.7391667366027832
Epoch 8.6: Loss = 0.7207366228103638
Epoch 8.7: Loss = 0.7091090083122253
Epoch 8.8: Loss = 0.7483408451080322
Epoch 8.9: Loss = 0.7539477348327637
Epoch 8.10: Loss = 0.7736960649490356
Epoch 8.11: Loss = 0.7393779754638672
Epoch 8.12: Loss = 0.7378624677658081
Epoch 8.13: Loss = 0.7304872274398804
Epoch 8.14: Loss = 0.7593473792076111
Epoch 8.15: Loss = 0.7747373580932617
Epoch 8.16: Loss = 0.6901075839996338
Epoch 8.17: Loss = 0.7480081915855408
Epoch 8.18: Loss = 0.7270941138267517
Epoch 8.19: Loss = 0.7743046283721924
Epoch 8.20: Loss = 0.7057225704193115
Epoch 8.21: Loss = 0.7149175405502319
Epoch 8.22: Loss = 0.7332942485809326
Epoch 8.23: Loss = 0.7932375073432922
Epoch 8.24: Loss = 0.7243627309799194
Epoch 8.25: Loss = 0.687893807888031
Epoch 8.26: Loss = 0.7392396926879883
Epoch 8.27: Loss = 0.7616747617721558
Epoch 8.28: Loss = 0.7085383534431458
Epoch 8.29: Loss = 0.7282876968383789
Epoch 8.30: Loss = 0.7065428495407104
	Test set:Loss: 0.780487 Acc@1: 0.745300 
Epoch 9.1: Loss = 0.7508972883224487
	Train Epoch: 9 	Loss: 0.750897 Acc@1: 0.754000 (ε = 0.52, δ = 1e-05)
Epoch 9.2: Loss = 0.7862952351570129
Epoch 9.3: Loss = 0.700755774974823
Epoch 9.4: Loss = 0.7642651200294495
Epoch 9.5: Loss = 0.7365253567695618
Epoch 9.6: Loss = 0.7194876074790955
Epoch 9.7: Loss = 0.7014978528022766
Epoch 9.8: Loss = 0.7465318441390991
Epoch 9.9: Loss = 0.7509085536003113
Epoch 9.10: Loss = 0.7720547914505005
Epoch 9.11: Loss = 0.7290490865707397
Epoch 9.12: Loss = 0.733662486076355
Epoch 9.13: Loss = 0.7279344797134399
Epoch 9.14: Loss = 0.7558013796806335
Epoch 9.15: Loss = 0.7717052698135376
Epoch 9.16: Loss = 0.677993655204773
Epoch 9.17: Loss = 0.7454805374145508
Epoch 9.18: Loss = 0.7217850685119629
Epoch 9.19: Loss = 0.7720239162445068
Epoch 9.20: Loss = 0.6997299790382385
Epoch 9.21: Loss = 0.7074868083000183
Epoch 9.22: Loss = 0.7316084504127502
Epoch 9.23: Loss = 0.791594386100769
Epoch 9.24: Loss = 0.7188999652862549
Epoch 9.25: Loss = 0.685794472694397
Epoch 9.26: Loss = 0.720810055732727
Epoch 9.27: Loss = 0.7605655789375305
Epoch 9.28: Loss = 0.7026630640029907
Epoch 9.29: Loss = 0.7420830130577087
Epoch 9.30: Loss = 0.707436740398407
	Test set:Loss: 0.775228 Acc@1: 0.752400 
Epoch 10.1: Loss = 0.7439841628074646
	Train Epoch: 10 	Loss: 0.743984 Acc@1: 0.767500 (ε = 0.55, δ = 1e-05)
Epoch 10.2: Loss = 0.7840572595596313
Epoch 10.3: Loss = 0.694817304611206
Epoch 10.4: Loss = 0.7627479434013367
Epoch 10.5: Loss = 0.7336389422416687
Epoch 10.6: Loss = 0.7156199812889099
Epoch 10.7: Loss = 0.6881504058837891
Epoch 10.8: Loss = 0.7443443536758423
Epoch 10.9: Loss = 0.7385445833206177
Epoch 10.10: Loss = 0.7672277688980103
Epoch 10.11: Loss = 0.7203009724617004
Epoch 10.12: Loss = 0.7284567952156067
Epoch 10.13: Loss = 0.7179439663887024
Epoch 10.14: Loss = 0.7502239346504211
Epoch 10.15: Loss = 0.763174295425415
Epoch 10.16: Loss = 0.6677558422088623
Epoch 10.17: Loss = 0.7285207509994507
Epoch 10.18: Loss = 0.7245150804519653
Epoch 10.19: Loss = 0.7500282526016235
Epoch 10.20: Loss = 0.6942239999771118
Epoch 10.21: Loss = 0.6946768760681152
Epoch 10.22: Loss = 0.7212690711021423
Epoch 10.23: Loss = 0.785199761390686
Epoch 10.24: Loss = 0.7142357230186462
Epoch 10.25: Loss = 0.6829426288604736
Epoch 10.26: Loss = 0.7139942049980164
Epoch 10.27: Loss = 0.7499086856842041
Epoch 10.28: Loss = 0.6989270448684692
Epoch 10.29: Loss = 0.7378824353218079
Epoch 10.30: Loss = 0.7021492123603821
	Test set:Loss: 0.766292 Acc@1: 0.756500 
