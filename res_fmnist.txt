BATCH SIZE = 2000 CLIP FACTOR = 4.0 	SIGMA = 4.0
Epoch 1.1: Loss = 2.308140516281128
	Train Epoch: 1 	Loss: 2.308141 Acc@1: 0.081500 (ε = 0.11, δ = 1e-05)
Epoch 1.2: Loss = 2.289261817932129
Epoch 1.3: Loss = 2.2725987434387207
Epoch 1.4: Loss = 2.2561709880828857
Epoch 1.5: Loss = 2.234584093093872
Epoch 1.6: Loss = 2.216428279876709
Epoch 1.7: Loss = 2.19307541847229
Epoch 1.8: Loss = 2.1683883666992188
Epoch 1.9: Loss = 2.1415412425994873
Epoch 1.10: Loss = 2.1107370853424072
Epoch 1.11: Loss = 2.070016622543335
Epoch 1.12: Loss = 2.031572103500366
Epoch 1.13: Loss = 1.98520827293396
Epoch 1.14: Loss = 1.9463551044464111
Epoch 1.15: Loss = 1.90239417552948
Epoch 1.16: Loss = 1.8415323495864868
Epoch 1.17: Loss = 1.7885323762893677
Epoch 1.18: Loss = 1.7221800088882446
Epoch 1.19: Loss = 1.6814823150634766
Epoch 1.20: Loss = 1.620215892791748
Epoch 1.21: Loss = 1.5814157724380493
Epoch 1.22: Loss = 1.5242053270339966
Epoch 1.23: Loss = 1.4842886924743652
Epoch 1.24: Loss = 1.4465376138687134
Epoch 1.25: Loss = 1.381477952003479
Epoch 1.26: Loss = 1.3769999742507935
Epoch 1.27: Loss = 1.339785099029541
Epoch 1.28: Loss = 1.301213026046753
Epoch 1.29: Loss = 1.2686712741851807
Epoch 1.30: Loss = 1.2524781227111816
	Test set:Loss: 1.233289 Acc@1: 0.554500 
Epoch 2.1: Loss = 1.2163554430007935
	Train Epoch: 2 	Loss: 1.216355 Acc@1: 0.568000 (ε = 0.18, δ = 1e-05)
Epoch 2.2: Loss = 1.2117527723312378
Epoch 2.3: Loss = 1.166955828666687
Epoch 2.4: Loss = 1.169684648513794
Epoch 2.5: Loss = 1.1673424243927002
Epoch 2.6: Loss = 1.1415766477584839
Epoch 2.7: Loss = 1.1119434833526611
Epoch 2.8: Loss = 1.1148686408996582
Epoch 2.9: Loss = 1.1061757802963257
Epoch 2.10: Loss = 1.0918601751327515
Epoch 2.11: Loss = 1.082317590713501
Epoch 2.12: Loss = 1.0547922849655151
Epoch 2.13: Loss = 1.0497640371322632
Epoch 2.14: Loss = 1.0469424724578857
Epoch 2.15: Loss = 1.0608323812484741
Epoch 2.16: Loss = 1.002183198928833
Epoch 2.17: Loss = 1.001705527305603
Epoch 2.18: Loss = 0.9858653545379639
Epoch 2.19: Loss = 1.006186604499817
Epoch 2.20: Loss = 0.9653815031051636
Epoch 2.21: Loss = 0.9736713767051697
Epoch 2.22: Loss = 0.9781703948974609
Epoch 2.23: Loss = 0.9825966358184814
Epoch 2.24: Loss = 0.967560350894928
Epoch 2.25: Loss = 0.9064218401908875
Epoch 2.26: Loss = 0.9820893406867981
Epoch 2.27: Loss = 0.9523544907569885
Epoch 2.28: Loss = 0.9142900109291077
Epoch 2.29: Loss = 0.9164966344833374
Epoch 2.30: Loss = 0.9154990911483765
	Test set:Loss: 0.932220 Acc@1: 0.634000 
Epoch 3.1: Loss = 0.9136229157447815
	Train Epoch: 3 	Loss: 0.913623 Acc@1: 0.653000 (ε = 0.26, δ = 1e-05)
Epoch 3.2: Loss = 0.9459986090660095
Epoch 3.3: Loss = 0.8700742125511169
Epoch 3.4: Loss = 0.9160231947898865
Epoch 3.5: Loss = 0.9219287633895874
Epoch 3.6: Loss = 0.9074981808662415
Epoch 3.7: Loss = 0.8786152601242065
Epoch 3.8: Loss = 0.9010704159736633
Epoch 3.9: Loss = 0.9076718688011169
Epoch 3.10: Loss = 0.9022601246833801
Epoch 3.11: Loss = 0.8971203565597534
Epoch 3.12: Loss = 0.8725258111953735
Epoch 3.13: Loss = 0.8910627961158752
Epoch 3.14: Loss = 0.8881360292434692
Epoch 3.15: Loss = 0.9030978679656982
Epoch 3.16: Loss = 0.8380796313285828
Epoch 3.17: Loss = 0.8588958382606506
Epoch 3.18: Loss = 0.8444981575012207
Epoch 3.19: Loss = 0.8809589147567749
Epoch 3.20: Loss = 0.8347842693328857
Epoch 3.21: Loss = 0.8411163687705994
Epoch 3.22: Loss = 0.8545457124710083
Epoch 3.23: Loss = 0.8799914717674255
Epoch 3.24: Loss = 0.8599258065223694
Epoch 3.25: Loss = 0.794000506401062
Epoch 3.26: Loss = 0.8782247304916382
Epoch 3.27: Loss = 0.8553338646888733
Epoch 3.28: Loss = 0.8137086629867554
Epoch 3.29: Loss = 0.824152946472168
Epoch 3.30: Loss = 0.815788984298706
	Test set:Loss: 0.853251 Acc@1: 0.668300 
Epoch 4.1: Loss = 0.8368251919746399
	Train Epoch: 4 	Loss: 0.836825 Acc@1: 0.677500 (ε = 0.31, δ = 1e-05)
Epoch 4.2: Loss = 0.8691778182983398
Epoch 4.3: Loss = 0.7835023403167725
Epoch 4.4: Loss = 0.8435535430908203
Epoch 4.5: Loss = 0.8435418605804443
Epoch 4.6: Loss = 0.8300480842590332
Epoch 4.7: Loss = 0.8040542602539062
Epoch 4.8: Loss = 0.8267449736595154
Epoch 4.9: Loss = 0.8338837027549744
Epoch 4.10: Loss = 0.8409374356269836
Epoch 4.11: Loss = 0.8311876058578491
Epoch 4.12: Loss = 0.80712890625
Epoch 4.13: Loss = 0.8254703283309937
Epoch 4.14: Loss = 0.8272227048873901
Epoch 4.15: Loss = 0.8454253673553467
Epoch 4.16: Loss = 0.7768117189407349
Epoch 4.17: Loss = 0.8040056228637695
Epoch 4.18: Loss = 0.7912840247154236
Epoch 4.19: Loss = 0.8360399603843689
Epoch 4.20: Loss = 0.7794665694236755
Epoch 4.21: Loss = 0.7879612445831299
Epoch 4.22: Loss = 0.7978770136833191
Epoch 4.23: Loss = 0.8431805372238159
Epoch 4.24: Loss = 0.8090834617614746
Epoch 4.25: Loss = 0.7484827041625977
Epoch 4.26: Loss = 0.8187680840492249
Epoch 4.27: Loss = 0.8168776035308838
Epoch 4.28: Loss = 0.7669945359230042
Epoch 4.29: Loss = 0.7838014960289001
Epoch 4.30: Loss = 0.7692254185676575
	Test set:Loss: 0.811335 Acc@1: 0.699000 
Epoch 5.1: Loss = 0.793308436870575
	Train Epoch: 5 	Loss: 0.793308 Acc@1: 0.711000 (ε = 0.36, δ = 1e-05)
Epoch 5.2: Loss = 0.8282853364944458
Epoch 5.3: Loss = 0.7435247898101807
Epoch 5.4: Loss = 0.8083142042160034
Epoch 5.5: Loss = 0.7976827621459961
Epoch 5.6: Loss = 0.7855984568595886
Epoch 5.7: Loss = 0.7624449729919434
Epoch 5.8: Loss = 0.7880358695983887
Epoch 5.9: Loss = 0.7886349558830261
Epoch 5.10: Loss = 0.8036519885063171
Epoch 5.11: Loss = 0.7912108898162842
Epoch 5.12: Loss = 0.7693983912467957
Epoch 5.13: Loss = 0.7858402729034424
Epoch 5.14: Loss = 0.7950946092605591
Epoch 5.15: Loss = 0.8110246062278748
Epoch 5.16: Loss = 0.7367268800735474
Epoch 5.17: Loss = 0.7718304395675659
Epoch 5.18: Loss = 0.7609102129936218
Epoch 5.19: Loss = 0.8014446496963501
Epoch 5.20: Loss = 0.7420656681060791
Epoch 5.21: Loss = 0.7498236894607544
Epoch 5.22: Loss = 0.770336925983429
Epoch 5.23: Loss = 0.8186816573143005
Epoch 5.24: Loss = 0.7727679014205933
Epoch 5.25: Loss = 0.7142931222915649
Epoch 5.26: Loss = 0.7836213707923889
Epoch 5.27: Loss = 0.7823310494422913
Epoch 5.28: Loss = 0.7350892424583435
Epoch 5.29: Loss = 0.755889356136322
Epoch 5.30: Loss = 0.7389003038406372
	Test set:Loss: 0.792558 Acc@1: 0.718400 
Epoch 6.1: Loss = 0.772135317325592
	Train Epoch: 6 	Loss: 0.772135 Acc@1: 0.729000 (ε = 0.41, δ = 1e-05)
Epoch 6.2: Loss = 0.8115864992141724
Epoch 6.3: Loss = 0.714584469795227
Epoch 6.4: Loss = 0.7864714860916138
Epoch 6.5: Loss = 0.772906482219696
Epoch 6.6: Loss = 0.7580572962760925
Epoch 6.7: Loss = 0.7334333062171936
Epoch 6.8: Loss = 0.7665289044380188
Epoch 6.9: Loss = 0.7698320150375366
Epoch 6.10: Loss = 0.7881796956062317
Epoch 6.11: Loss = 0.7644422054290771
Epoch 6.12: Loss = 0.7512943148612976
Epoch 6.13: Loss = 0.7588441967964172
Epoch 6.14: Loss = 0.7768954038619995
Epoch 6.15: Loss = 0.7883889675140381
Epoch 6.16: Loss = 0.7142749428749084
Epoch 6.17: Loss = 0.7533281445503235
Epoch 6.18: Loss = 0.7451649308204651
Epoch 6.19: Loss = 0.790378749370575
Epoch 6.20: Loss = 0.726021945476532
Epoch 6.21: Loss = 0.7333698868751526
Epoch 6.22: Loss = 0.7516964077949524
Epoch 6.23: Loss = 0.8055228590965271
Epoch 6.24: Loss = 0.7532752752304077
Epoch 6.25: Loss = 0.7041468620300293
Epoch 6.26: Loss = 0.7684372663497925
Epoch 6.27: Loss = 0.7715141177177429
Epoch 6.28: Loss = 0.7175304293632507
Epoch 6.29: Loss = 0.7420225143432617
Epoch 6.30: Loss = 0.7186471819877625
	Test set:Loss: 0.775356 Acc@1: 0.727800 
Epoch 7.1: Loss = 0.7522465586662292
	Train Epoch: 7 	Loss: 0.752247 Acc@1: 0.737500 (ε = 0.45, δ = 1e-05)
Epoch 7.2: Loss = 0.7926269769668579
Epoch 7.3: Loss = 0.7019496560096741
Epoch 7.4: Loss = 0.7690821290016174
Epoch 7.5: Loss = 0.7509210109710693
Epoch 7.6: Loss = 0.7444932460784912
Epoch 7.7: Loss = 0.7154620885848999
Epoch 7.8: Loss = 0.7490774989128113
Epoch 7.9: Loss = 0.7503417730331421
Epoch 7.10: Loss = 0.7732091546058655
Epoch 7.11: Loss = 0.7439624071121216
Epoch 7.12: Loss = 0.7368733286857605
Epoch 7.13: Loss = 0.7450222969055176
Epoch 7.14: Loss = 0.7628482580184937
Epoch 7.15: Loss = 0.7710915803909302
Epoch 7.16: Loss = 0.6947748064994812
Epoch 7.17: Loss = 0.7363801002502441
Epoch 7.18: Loss = 0.7325674891471863
Epoch 7.19: Loss = 0.7745472192764282
Epoch 7.20: Loss = 0.7088893055915833
Epoch 7.21: Loss = 0.7161162495613098
Epoch 7.22: Loss = 0.7325901389122009
Epoch 7.23: Loss = 0.793869137763977
Epoch 7.24: Loss = 0.7373819947242737
Epoch 7.25: Loss = 0.6888166666030884
Epoch 7.26: Loss = 0.7463175654411316
Epoch 7.27: Loss = 0.7535917162895203
Epoch 7.28: Loss = 0.7065669298171997
Epoch 7.29: Loss = 0.7265290021896362
Epoch 7.30: Loss = 0.7056659460067749
	Test set:Loss: 0.767728 Acc@1: 0.738700 
Epoch 8.1: Loss = 0.7407178282737732
	Train Epoch: 8 	Loss: 0.740718 Acc@1: 0.744000 (ε = 0.49, δ = 1e-05)
Epoch 8.2: Loss = 0.7840920090675354
Epoch 8.3: Loss = 0.6902540922164917
Epoch 8.4: Loss = 0.7670079469680786
Epoch 8.5: Loss = 0.7395241856575012
Epoch 8.6: Loss = 0.7254805564880371
Epoch 8.7: Loss = 0.7029995918273926
Epoch 8.8: Loss = 0.7429721355438232
Epoch 8.9: Loss = 0.7422043085098267
Epoch 8.10: Loss = 0.7692766189575195
Epoch 8.11: Loss = 0.7354741096496582
Epoch 8.12: Loss = 0.7291976809501648
Epoch 8.13: Loss = 0.7290528416633606
Epoch 8.14: Loss = 0.7539053559303284
Epoch 8.15: Loss = 0.769037127494812
Epoch 8.16: Loss = 0.6847817897796631
Epoch 8.17: Loss = 0.729025661945343
Epoch 8.18: Loss = 0.7269101142883301
Epoch 8.19: Loss = 0.7633666396141052
Epoch 8.20: Loss = 0.6962023973464966
Epoch 8.21: Loss = 0.7079951763153076
Epoch 8.22: Loss = 0.7287037372589111
Epoch 8.23: Loss = 0.7895002365112305
Epoch 8.24: Loss = 0.728376030921936
Epoch 8.25: Loss = 0.6818862557411194
Epoch 8.26: Loss = 0.7282620668411255
Epoch 8.27: Loss = 0.7495989203453064
Epoch 8.28: Loss = 0.7029110789299011
Epoch 8.29: Loss = 0.725132942199707
Epoch 8.30: Loss = 0.6970293521881104
	Test set:Loss: 0.768438 Acc@1: 0.747800 
Epoch 9.1: Loss = 0.7393876910209656
	Train Epoch: 9 	Loss: 0.739388 Acc@1: 0.749000 (ε = 0.52, δ = 1e-05)
Epoch 9.2: Loss = 0.7815788388252258
Epoch 9.3: Loss = 0.6866344809532166
Epoch 9.4: Loss = 0.769256055355072
Epoch 9.5: Loss = 0.7347418665885925
Epoch 9.6: Loss = 0.7213066816329956
Epoch 9.7: Loss = 0.6943807601928711
Epoch 9.8: Loss = 0.7373958826065063
Epoch 9.9: Loss = 0.7392342686653137
Epoch 9.10: Loss = 0.762896716594696
Epoch 9.11: Loss = 0.7322845458984375
Epoch 9.12: Loss = 0.7254543304443359
Epoch 9.13: Loss = 0.7233023047447205
Epoch 9.14: Loss = 0.7486073970794678
Epoch 9.15: Loss = 0.7575171589851379
Epoch 9.16: Loss = 0.6791247725486755
Epoch 9.17: Loss = 0.7309197783470154
Epoch 9.18: Loss = 0.7218978404998779
Epoch 9.19: Loss = 0.7488334774971008
Epoch 9.20: Loss = 0.687351644039154
Epoch 9.21: Loss = 0.6974976062774658
Epoch 9.22: Loss = 0.7179429531097412
Epoch 9.23: Loss = 0.7868561744689941
Epoch 9.24: Loss = 0.7166483998298645
Epoch 9.25: Loss = 0.6719551682472229
Epoch 9.26: Loss = 0.7133205533027649
Epoch 9.27: Loss = 0.7460997700691223
Epoch 9.28: Loss = 0.6972962617874146
Epoch 9.29: Loss = 0.7199745774269104
Epoch 9.30: Loss = 0.6985993385314941
	Test set:Loss: 0.766477 Acc@1: 0.752100 
Epoch 10.1: Loss = 0.7318323850631714
	Train Epoch: 10 	Loss: 0.731832 Acc@1: 0.756500 (ε = 0.55, δ = 1e-05)
Epoch 10.2: Loss = 0.7736843228340149
Epoch 10.3: Loss = 0.6795830726623535
Epoch 10.4: Loss = 0.7602574229240417
Epoch 10.5: Loss = 0.7250503301620483
Epoch 10.6: Loss = 0.7105011940002441
Epoch 10.7: Loss = 0.680962324142456
Epoch 10.8: Loss = 0.7315011024475098
Epoch 10.9: Loss = 0.7323516607284546
Epoch 10.10: Loss = 0.7592227458953857
Epoch 10.11: Loss = 0.7172685265541077
Epoch 10.12: Loss = 0.71291583776474
Epoch 10.13: Loss = 0.7126068472862244
Epoch 10.14: Loss = 0.7339074015617371
Epoch 10.15: Loss = 0.7479264140129089
Epoch 10.16: Loss = 0.6612008213996887
Epoch 10.17: Loss = 0.7211552858352661
Epoch 10.18: Loss = 0.7095540165901184
Epoch 10.19: Loss = 0.7511693239212036
Epoch 10.20: Loss = 0.6805940866470337
Epoch 10.21: Loss = 0.6892192363739014
Epoch 10.22: Loss = 0.706201434135437
Epoch 10.23: Loss = 0.773978054523468
Epoch 10.24: Loss = 0.7120126485824585
Epoch 10.25: Loss = 0.6736696362495422
Epoch 10.26: Loss = 0.7026561498641968
Epoch 10.27: Loss = 0.7414594888687134
Epoch 10.28: Loss = 0.6910817623138428
Epoch 10.29: Loss = 0.7154965996742249
Epoch 10.30: Loss = 0.6859070658683777
	Test set:Loss: 0.760212 Acc@1: 0.760500 
