BATCH SIZE = 2000 CLIP FACTOR = 4.0 	SIGMA = 1.0
Epoch 1.1: Loss = 2.308140516281128
	Train Epoch: 1 	Loss: 2.308141 Acc@1: 0.081500 (ε = 1.38, δ = 1e-05)
Epoch 1.2: Loss = 2.2895727157592773
Epoch 1.3: Loss = 2.2737574577331543
Epoch 1.4: Loss = 2.2571122646331787
Epoch 1.5: Loss = 2.235727548599243
Epoch 1.6: Loss = 2.2182717323303223
Epoch 1.7: Loss = 2.194713830947876
Epoch 1.8: Loss = 2.1699228286743164
Epoch 1.9: Loss = 2.1431849002838135
Epoch 1.10: Loss = 2.111757755279541
Epoch 1.11: Loss = 2.0717012882232666
Epoch 1.12: Loss = 2.0340240001678467
Epoch 1.13: Loss = 1.9859808683395386
Epoch 1.14: Loss = 1.946962833404541
Epoch 1.15: Loss = 1.9004064798355103
Epoch 1.16: Loss = 1.8382766246795654
Epoch 1.17: Loss = 1.7827357053756714
Epoch 1.18: Loss = 1.7150335311889648
Epoch 1.19: Loss = 1.6723822355270386
Epoch 1.20: Loss = 1.6093509197235107
Epoch 1.21: Loss = 1.5705965757369995
Epoch 1.22: Loss = 1.513578176498413
Epoch 1.23: Loss = 1.47152841091156
Epoch 1.24: Loss = 1.4341470003128052
Epoch 1.25: Loss = 1.369552731513977
Epoch 1.26: Loss = 1.367880940437317
Epoch 1.27: Loss = 1.3307782411575317
Epoch 1.28: Loss = 1.293054461479187
Epoch 1.29: Loss = 1.259960651397705
Epoch 1.30: Loss = 1.2441028356552124
	Test set:Loss: 1.225136 Acc@1: 0.559200 
Epoch 2.1: Loss = 1.2089097499847412
	Train Epoch: 2 	Loss: 1.208910 Acc@1: 0.570500 (ε = 2.05, δ = 1e-05)
Epoch 2.2: Loss = 1.203579306602478
Epoch 2.3: Loss = 1.1566733121871948
Epoch 2.4: Loss = 1.1606260538101196
Epoch 2.5: Loss = 1.1602658033370972
Epoch 2.6: Loss = 1.1337213516235352
Epoch 2.7: Loss = 1.105195164680481
Epoch 2.8: Loss = 1.1065071821212769
Epoch 2.9: Loss = 1.1005107164382935
Epoch 2.10: Loss = 1.0890369415283203
Epoch 2.11: Loss = 1.07662832736969
Epoch 2.12: Loss = 1.0507811307907104
Epoch 2.13: Loss = 1.0455824136734009
Epoch 2.14: Loss = 1.042733907699585
Epoch 2.15: Loss = 1.0560489892959595
Epoch 2.16: Loss = 0.9965129494667053
Epoch 2.17: Loss = 0.9978958964347839
Epoch 2.18: Loss = 0.9816496968269348
Epoch 2.19: Loss = 1.0046026706695557
Epoch 2.20: Loss = 0.9629395604133606
Epoch 2.21: Loss = 0.9691755175590515
Epoch 2.22: Loss = 0.9755154848098755
Epoch 2.23: Loss = 0.9817547798156738
Epoch 2.24: Loss = 0.9636110663414001
Epoch 2.25: Loss = 0.9043695330619812
Epoch 2.26: Loss = 0.9799883365631104
Epoch 2.27: Loss = 0.9533441662788391
Epoch 2.28: Loss = 0.9132198095321655
Epoch 2.29: Loss = 0.914725124835968
Epoch 2.30: Loss = 0.9137189388275146
	Test set:Loss: 0.930269 Acc@1: 0.633300 
Epoch 3.1: Loss = 0.9133695363998413
	Train Epoch: 3 	Loss: 0.913370 Acc@1: 0.650500 (ε = 2.41, δ = 1e-05)
Epoch 3.2: Loss = 0.9414757490158081
Epoch 3.3: Loss = 0.8688428997993469
Epoch 3.4: Loss = 0.9132143259048462
Epoch 3.5: Loss = 0.9199203848838806
Epoch 3.6: Loss = 0.9069910645484924
Epoch 3.7: Loss = 0.8785029649734497
Epoch 3.8: Loss = 0.8981752991676331
Epoch 3.9: Loss = 0.9096742868423462
Epoch 3.10: Loss = 0.9042569398880005
Epoch 3.11: Loss = 0.8954765796661377
Epoch 3.12: Loss = 0.8727688789367676
Epoch 3.13: Loss = 0.887113094329834
Epoch 3.14: Loss = 0.8857093453407288
Epoch 3.15: Loss = 0.9046030044555664
Epoch 3.16: Loss = 0.8380480408668518
Epoch 3.17: Loss = 0.8590267300605774
Epoch 3.18: Loss = 0.844941258430481
Epoch 3.19: Loss = 0.8833245038986206
Epoch 3.20: Loss = 0.8326441049575806
Epoch 3.21: Loss = 0.8397616744041443
Epoch 3.22: Loss = 0.8529645204544067
Epoch 3.23: Loss = 0.8802347779273987
Epoch 3.24: Loss = 0.8540330529212952
Epoch 3.25: Loss = 0.7947052121162415
Epoch 3.26: Loss = 0.8758847117424011
Epoch 3.27: Loss = 0.8563398718833923
Epoch 3.28: Loss = 0.8133063316345215
Epoch 3.29: Loss = 0.8207912445068359
Epoch 3.30: Loss = 0.8164403438568115
	Test set:Loss: 0.850346 Acc@1: 0.667400 
Epoch 4.1: Loss = 0.8357292413711548
	Train Epoch: 4 	Loss: 0.835729 Acc@1: 0.679000 (ε = 2.71, δ = 1e-05)
Epoch 4.2: Loss = 0.8666527271270752
Epoch 4.3: Loss = 0.7830380201339722
Epoch 4.4: Loss = 0.841039776802063
Epoch 4.5: Loss = 0.8413755893707275
Epoch 4.6: Loss = 0.8318241834640503
Epoch 4.7: Loss = 0.8059682250022888
Epoch 4.8: Loss = 0.8275077939033508
Epoch 4.9: Loss = 0.8362969160079956
Epoch 4.10: Loss = 0.8426350951194763
Epoch 4.11: Loss = 0.8308981657028198
Epoch 4.12: Loss = 0.8080915808677673
Epoch 4.13: Loss = 0.8263716101646423
Epoch 4.14: Loss = 0.8267365097999573
Epoch 4.15: Loss = 0.8485406637191772
Epoch 4.16: Loss = 0.7812667489051819
Epoch 4.17: Loss = 0.8066022992134094
Epoch 4.18: Loss = 0.795830249786377
Epoch 4.19: Loss = 0.8374009728431702
Epoch 4.20: Loss = 0.7824246883392334
Epoch 4.21: Loss = 0.7875015139579773
Epoch 4.22: Loss = 0.8050470352172852
Epoch 4.23: Loss = 0.8429619073867798
Epoch 4.24: Loss = 0.8092203736305237
Epoch 4.25: Loss = 0.751550555229187
Epoch 4.26: Loss = 0.8298026919364929
Epoch 4.27: Loss = 0.8183843493461609
Epoch 4.28: Loss = 0.7710710763931274
Epoch 4.29: Loss = 0.7837236523628235
Epoch 4.30: Loss = 0.7728362083435059
	Test set:Loss: 0.816449 Acc@1: 0.695000 
Epoch 5.1: Loss = 0.8013626933097839
	Train Epoch: 5 	Loss: 0.801363 Acc@1: 0.708000 (ε = 2.97, δ = 1e-05)
Epoch 5.2: Loss = 0.8369881510734558
Epoch 5.3: Loss = 0.7446868419647217
Epoch 5.4: Loss = 0.808617353439331
Epoch 5.5: Loss = 0.8028351664543152
Epoch 5.6: Loss = 0.7909165620803833
Epoch 5.7: Loss = 0.7675815224647522
Epoch 5.8: Loss = 0.7938494086265564
Epoch 5.9: Loss = 0.7975185513496399
Epoch 5.10: Loss = 0.8111414909362793
Epoch 5.11: Loss = 0.7941100001335144
Epoch 5.12: Loss = 0.7757834196090698
Epoch 5.13: Loss = 0.7888051867485046
Epoch 5.14: Loss = 0.7976480722427368
Epoch 5.15: Loss = 0.8168333768844604
Epoch 5.16: Loss = 0.7439110279083252
Epoch 5.17: Loss = 0.7757891416549683
Epoch 5.18: Loss = 0.7670469880104065
Epoch 5.19: Loss = 0.8088056445121765
Epoch 5.20: Loss = 0.7524502277374268
Epoch 5.21: Loss = 0.756980836391449
Epoch 5.22: Loss = 0.7760942578315735
Epoch 5.23: Loss = 0.8216763138771057
Epoch 5.24: Loss = 0.7751601338386536
Epoch 5.25: Loss = 0.724021852016449
Epoch 5.26: Loss = 0.7964963316917419
Epoch 5.27: Loss = 0.7913925647735596
Epoch 5.28: Loss = 0.7423885464668274
Epoch 5.29: Loss = 0.7586042881011963
Epoch 5.30: Loss = 0.7445225715637207
	Test set:Loss: 0.796502 Acc@1: 0.715000 
Epoch 6.1: Loss = 0.7799802422523499
	Train Epoch: 6 	Loss: 0.779980 Acc@1: 0.725500 (ε = 3.22, δ = 1e-05)
Epoch 6.2: Loss = 0.8184679746627808
Epoch 6.3: Loss = 0.7206277251243591
Epoch 6.4: Loss = 0.7902263402938843
Epoch 6.5: Loss = 0.7772064208984375
Epoch 6.6: Loss = 0.7592119574546814
Epoch 6.7: Loss = 0.7399657964706421
Epoch 6.8: Loss = 0.7721379399299622
Epoch 6.9: Loss = 0.7715612053871155
Epoch 6.10: Loss = 0.7912642359733582
Epoch 6.11: Loss = 0.7664244174957275
Epoch 6.12: Loss = 0.7521274089813232
Epoch 6.13: Loss = 0.7632923722267151
Epoch 6.14: Loss = 0.7792731523513794
Epoch 6.15: Loss = 0.7965267300605774
Epoch 6.16: Loss = 0.7181631326675415
Epoch 6.17: Loss = 0.7557815313339233
Epoch 6.18: Loss = 0.7478308081626892
Epoch 6.19: Loss = 0.7882195711135864
Epoch 6.20: Loss = 0.7296572327613831
Epoch 6.21: Loss = 0.7345031499862671
Epoch 6.22: Loss = 0.7553848028182983
Epoch 6.23: Loss = 0.8077560067176819
Epoch 6.24: Loss = 0.7523075342178345
Epoch 6.25: Loss = 0.706616222858429
Epoch 6.26: Loss = 0.772284984588623
Epoch 6.27: Loss = 0.7754729986190796
Epoch 6.28: Loss = 0.7244490385055542
Epoch 6.29: Loss = 0.7418770790100098
Epoch 6.30: Loss = 0.72528076171875
	Test set:Loss: 0.781782 Acc@1: 0.731300 
Epoch 7.1: Loss = 0.7633180022239685
	Train Epoch: 7 	Loss: 0.763318 Acc@1: 0.739000 (ε = 3.45, δ = 1e-05)
Epoch 7.2: Loss = 0.8038071990013123
Epoch 7.3: Loss = 0.7035524249076843
Epoch 7.4: Loss = 0.7749016284942627
Epoch 7.5: Loss = 0.7571074366569519
Epoch 7.6: Loss = 0.7396038770675659
Epoch 7.7: Loss = 0.720359742641449
Epoch 7.8: Loss = 0.7572299838066101
Epoch 7.9: Loss = 0.7574613690376282
Epoch 7.10: Loss = 0.7782930731773376
Epoch 7.11: Loss = 0.7475524544715881
Epoch 7.12: Loss = 0.7385556101799011
Epoch 7.13: Loss = 0.7455891966819763
Epoch 7.14: Loss = 0.7659362554550171
Epoch 7.15: Loss = 0.7823705673217773
Epoch 7.16: Loss = 0.6993602514266968
Epoch 7.17: Loss = 0.7425638437271118
Epoch 7.18: Loss = 0.7351560592651367
Epoch 7.19: Loss = 0.7749673128128052
Epoch 7.20: Loss = 0.7138563394546509
Epoch 7.21: Loss = 0.7193729281425476
Epoch 7.22: Loss = 0.740609347820282
Epoch 7.23: Loss = 0.7994703054428101
Epoch 7.24: Loss = 0.7391032576560974
Epoch 7.25: Loss = 0.6948384642601013
Epoch 7.26: Loss = 0.7497474551200867
Epoch 7.27: Loss = 0.7649221420288086
Epoch 7.28: Loss = 0.711736798286438
Epoch 7.29: Loss = 0.7333252429962158
Epoch 7.30: Loss = 0.7127438187599182
	Test set:Loss: 0.773066 Acc@1: 0.740300 
Epoch 8.1: Loss = 0.7506874203681946
	Train Epoch: 8 	Loss: 0.750687 Acc@1: 0.746500 (ε = 3.66, δ = 1e-05)
Epoch 8.2: Loss = 0.7957081198692322
Epoch 8.3: Loss = 0.6952621936798096
Epoch 8.4: Loss = 0.7684156894683838
Epoch 8.5: Loss = 0.7449632287025452
Epoch 8.6: Loss = 0.724700391292572
Epoch 8.7: Loss = 0.7083913087844849
Epoch 8.8: Loss = 0.7475751638412476
Epoch 8.9: Loss = 0.7475489377975464
Epoch 8.10: Loss = 0.769485354423523
Epoch 8.11: Loss = 0.7341141700744629
Epoch 8.12: Loss = 0.7302253842353821
Epoch 8.13: Loss = 0.7324361205101013
Epoch 8.14: Loss = 0.7554506659507751
Epoch 8.15: Loss = 0.7722048163414001
Epoch 8.16: Loss = 0.6864889860153198
Epoch 8.17: Loss = 0.7363515496253967
Epoch 8.18: Loss = 0.7279996871948242
Epoch 8.19: Loss = 0.7671523094177246
Epoch 8.20: Loss = 0.7034396529197693
Epoch 8.21: Loss = 0.7077638506889343
Epoch 8.22: Loss = 0.7323285937309265
Epoch 8.23: Loss = 0.7931790351867676
Epoch 8.24: Loss = 0.7269062995910645
Epoch 8.25: Loss = 0.6863565444946289
Epoch 8.26: Loss = 0.7352001667022705
Epoch 8.27: Loss = 0.7601873278617859
Epoch 8.28: Loss = 0.7065148949623108
Epoch 8.29: Loss = 0.726750910282135
Epoch 8.30: Loss = 0.7057234048843384
	Test set:Loss: 0.769872 Acc@1: 0.746600 
Epoch 9.1: Loss = 0.7439731359481812
	Train Epoch: 9 	Loss: 0.743973 Acc@1: 0.750500 (ε = 3.87, δ = 1e-05)
Epoch 9.2: Loss = 0.7897212505340576
Epoch 9.3: Loss = 0.687350869178772
Epoch 9.4: Loss = 0.7648780941963196
Epoch 9.5: Loss = 0.7368314266204834
Epoch 9.6: Loss = 0.7145432829856873
Epoch 9.7: Loss = 0.7003795504570007
Epoch 9.8: Loss = 0.7441475987434387
Epoch 9.9: Loss = 0.742917537689209
Epoch 9.10: Loss = 0.7654000520706177
Epoch 9.11: Loss = 0.7261307835578918
Epoch 9.12: Loss = 0.7269617915153503
Epoch 9.13: Loss = 0.7265498638153076
Epoch 9.14: Loss = 0.7501368522644043
Epoch 9.15: Loss = 0.7684029936790466
Epoch 9.16: Loss = 0.6772802472114563
Epoch 9.17: Loss = 0.7340993285179138
Epoch 9.18: Loss = 0.7247112393379211
Epoch 9.19: Loss = 0.7610868811607361
Epoch 9.20: Loss = 0.6963939070701599
Epoch 9.21: Loss = 0.6997593641281128
Epoch 9.22: Loss = 0.7288671731948853
Epoch 9.23: Loss = 0.7914295196533203
Epoch 9.24: Loss = 0.7228001952171326
Epoch 9.25: Loss = 0.6822171807289124
Epoch 9.26: Loss = 0.727259635925293
Epoch 9.27: Loss = 0.7560908198356628
Epoch 9.28: Loss = 0.7033003568649292
Epoch 9.29: Loss = 0.7243688702583313
Epoch 9.30: Loss = 0.7023322582244873
	Test set:Loss: 0.766231 Acc@1: 0.752500 
Epoch 10.1: Loss = 0.7372819781303406
	Train Epoch: 10 	Loss: 0.737282 Acc@1: 0.764000 (ε = 4.06, δ = 1e-05)
Epoch 10.2: Loss = 0.7847573161125183
Epoch 10.3: Loss = 0.6861125230789185
Epoch 10.4: Loss = 0.7622053623199463
Epoch 10.5: Loss = 0.732469379901886
Epoch 10.6: Loss = 0.7071362733840942
Epoch 10.7: Loss = 0.6946714520454407
Epoch 10.8: Loss = 0.7413071393966675
Epoch 10.9: Loss = 0.7419275641441345
Epoch 10.10: Loss = 0.7587806582450867
Epoch 10.11: Loss = 0.7191727161407471
Epoch 10.12: Loss = 0.722137987613678
Epoch 10.13: Loss = 0.7193830013275146
Epoch 10.14: Loss = 0.7450233101844788
Epoch 10.15: Loss = 0.7661904096603394
Epoch 10.16: Loss = 0.6712858080863953
Epoch 10.17: Loss = 0.7296558618545532
Epoch 10.18: Loss = 0.7203735709190369
Epoch 10.19: Loss = 0.7554576396942139
Epoch 10.20: Loss = 0.6911041736602783
Epoch 10.21: Loss = 0.6962400078773499
Epoch 10.22: Loss = 0.720970869064331
Epoch 10.23: Loss = 0.7875351905822754
Epoch 10.24: Loss = 0.7167714834213257
Epoch 10.25: Loss = 0.6804185509681702
Epoch 10.26: Loss = 0.7184116244316101
Epoch 10.27: Loss = 0.7539824843406677
Epoch 10.28: Loss = 0.7009149789810181
Epoch 10.29: Loss = 0.7211484313011169
Epoch 10.30: Loss = 0.6987760663032532
	Test set:Loss: 0.763403 Acc@1: 0.757600 
