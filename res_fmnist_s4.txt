BATCH SIZE = 2000 CLIP FACTOR = 4.0 	SIGMA = 1.0
Epoch 1.1: Loss = 2.308140516281128
	Train Epoch: 1 	Loss: 2.308141 Acc@1: 0.081500 (ε = 1.38, δ = 1e-05)
Epoch 1.2: Loss = 2.2897114753723145
Epoch 1.3: Loss = 2.2741544246673584
Epoch 1.4: Loss = 2.2582952976226807
Epoch 1.5: Loss = 2.236804485321045
Epoch 1.6: Loss = 2.2193241119384766
Epoch 1.7: Loss = 2.196061849594116
Epoch 1.8: Loss = 2.171138048171997
Epoch 1.9: Loss = 2.1447367668151855
Epoch 1.10: Loss = 2.113351583480835
Epoch 1.11: Loss = 2.0731418132781982
Epoch 1.12: Loss = 2.035271167755127
Epoch 1.13: Loss = 1.9876420497894287
Epoch 1.14: Loss = 1.9487868547439575
Epoch 1.15: Loss = 1.9020575284957886
Epoch 1.16: Loss = 1.8407124280929565
Epoch 1.17: Loss = 1.7857248783111572
Epoch 1.18: Loss = 1.7173880338668823
Epoch 1.19: Loss = 1.6758086681365967
Epoch 1.20: Loss = 1.612853765487671
Epoch 1.21: Loss = 1.5737676620483398
Epoch 1.22: Loss = 1.5162224769592285
Epoch 1.23: Loss = 1.4737719297409058
Epoch 1.24: Loss = 1.4368942975997925
Epoch 1.25: Loss = 1.372324824333191
Epoch 1.26: Loss = 1.3712189197540283
Epoch 1.27: Loss = 1.3341952562332153
Epoch 1.28: Loss = 1.296531319618225
Epoch 1.29: Loss = 1.2628889083862305
Epoch 1.30: Loss = 1.2469836473464966
	Test set:Loss: 1.228681 Acc@1: 0.556400 
Epoch 2.1: Loss = 1.2123860120773315
	Train Epoch: 2 	Loss: 1.212386 Acc@1: 0.569000 (ε = 2.05, δ = 1e-05)
Epoch 2.2: Loss = 1.2062914371490479
Epoch 2.3: Loss = 1.1605467796325684
Epoch 2.4: Loss = 1.163461446762085
Epoch 2.5: Loss = 1.1633220911026
Epoch 2.6: Loss = 1.1368508338928223
Epoch 2.7: Loss = 1.1080358028411865
Epoch 2.8: Loss = 1.1098209619522095
Epoch 2.9: Loss = 1.1030367612838745
Epoch 2.10: Loss = 1.0908678770065308
Epoch 2.11: Loss = 1.0787845849990845
Epoch 2.12: Loss = 1.0534067153930664
Epoch 2.13: Loss = 1.0485926866531372
Epoch 2.14: Loss = 1.0455173254013062
Epoch 2.15: Loss = 1.0575416088104248
Epoch 2.16: Loss = 0.9997919797897339
Epoch 2.17: Loss = 1.000832200050354
Epoch 2.18: Loss = 0.9848552346229553
Epoch 2.19: Loss = 1.0066728591918945
Epoch 2.20: Loss = 0.9649143218994141
Epoch 2.21: Loss = 0.9719579219818115
Epoch 2.22: Loss = 0.9769006967544556
Epoch 2.23: Loss = 0.9835489392280579
Epoch 2.24: Loss = 0.9654906988143921
Epoch 2.25: Loss = 0.906000018119812
Epoch 2.26: Loss = 0.9833003878593445
Epoch 2.27: Loss = 0.9560648202896118
Epoch 2.28: Loss = 0.9148275256156921
Epoch 2.29: Loss = 0.9156769514083862
Epoch 2.30: Loss = 0.9151532053947449
	Test set:Loss: 0.931967 Acc@1: 0.632000 
Epoch 3.1: Loss = 0.9148996472358704
	Train Epoch: 3 	Loss: 0.914900 Acc@1: 0.649500 (ε = 2.41, δ = 1e-05)
Epoch 3.2: Loss = 0.9428629875183105
Epoch 3.3: Loss = 0.8707768321037292
Epoch 3.4: Loss = 0.9149429202079773
Epoch 3.5: Loss = 0.9222044348716736
Epoch 3.6: Loss = 0.9091770052909851
Epoch 3.7: Loss = 0.8788502216339111
Epoch 3.8: Loss = 0.8990342617034912
Epoch 3.9: Loss = 0.9110760688781738
Epoch 3.10: Loss = 0.904426634311676
Epoch 3.11: Loss = 0.895778238773346
Epoch 3.12: Loss = 0.8733084797859192
Epoch 3.13: Loss = 0.8878323435783386
Epoch 3.14: Loss = 0.8865929841995239
Epoch 3.15: Loss = 0.9045827388763428
Epoch 3.16: Loss = 0.839070737361908
Epoch 3.17: Loss = 0.8596315979957581
Epoch 3.18: Loss = 0.8452866673469543
Epoch 3.19: Loss = 0.8819499611854553
Epoch 3.20: Loss = 0.832355260848999
Epoch 3.21: Loss = 0.8396946787834167
Epoch 3.22: Loss = 0.8540805578231812
Epoch 3.23: Loss = 0.8811589479446411
Epoch 3.24: Loss = 0.856069803237915
Epoch 3.25: Loss = 0.795811653137207
Epoch 3.26: Loss = 0.8777684569358826
Epoch 3.27: Loss = 0.8567258715629578
Epoch 3.28: Loss = 0.8134113550186157
Epoch 3.29: Loss = 0.8227179646492004
Epoch 3.30: Loss = 0.8163983821868896
	Test set:Loss: 0.850659 Acc@1: 0.666800 
Epoch 4.1: Loss = 0.835990846157074
	Train Epoch: 4 	Loss: 0.835991 Acc@1: 0.676000 (ε = 2.71, δ = 1e-05)
Epoch 4.2: Loss = 0.868682324886322
Epoch 4.3: Loss = 0.7844045162200928
Epoch 4.4: Loss = 0.8426676988601685
Epoch 4.5: Loss = 0.8420725464820862
Epoch 4.6: Loss = 0.8336791396141052
Epoch 4.7: Loss = 0.806313157081604
Epoch 4.8: Loss = 0.8279297351837158
Epoch 4.9: Loss = 0.8344618678092957
Epoch 4.10: Loss = 0.8427338004112244
Epoch 4.11: Loss = 0.8312293887138367
Epoch 4.12: Loss = 0.8076735138893127
Epoch 4.13: Loss = 0.8271159529685974
Epoch 4.14: Loss = 0.8274221420288086
Epoch 4.15: Loss = 0.8476763367652893
Epoch 4.16: Loss = 0.7800871133804321
Epoch 4.17: Loss = 0.8076743483543396
Epoch 4.18: Loss = 0.7957810163497925
Epoch 4.19: Loss = 0.8355152606964111
Epoch 4.20: Loss = 0.7823505401611328
Epoch 4.21: Loss = 0.7881125807762146
Epoch 4.22: Loss = 0.805728018283844
Epoch 4.23: Loss = 0.8435781598091125
Epoch 4.24: Loss = 0.8095670342445374
Epoch 4.25: Loss = 0.7509692907333374
Epoch 4.26: Loss = 0.8296585083007812
Epoch 4.27: Loss = 0.8171783685684204
Epoch 4.28: Loss = 0.7718430161476135
Epoch 4.29: Loss = 0.7824710607528687
Epoch 4.30: Loss = 0.7731531858444214
	Test set:Loss: 0.815175 Acc@1: 0.696100 
Epoch 5.1: Loss = 0.8010753989219666
	Train Epoch: 5 	Loss: 0.801075 Acc@1: 0.708000 (ε = 2.97, δ = 1e-05)
Epoch 5.2: Loss = 0.8377301096916199
Epoch 5.3: Loss = 0.7449379563331604
Epoch 5.4: Loss = 0.8097995519638062
Epoch 5.5: Loss = 0.8025845289230347
Epoch 5.6: Loss = 0.7911846041679382
Epoch 5.7: Loss = 0.7663055062294006
Epoch 5.8: Loss = 0.7936674952507019
Epoch 5.9: Loss = 0.7958517074584961
Epoch 5.10: Loss = 0.8110004663467407
Epoch 5.11: Loss = 0.7952485084533691
Epoch 5.12: Loss = 0.773752748966217
Epoch 5.13: Loss = 0.7895500063896179
Epoch 5.14: Loss = 0.7988988757133484
Epoch 5.15: Loss = 0.8161791563034058
Epoch 5.16: Loss = 0.7432857751846313
Epoch 5.17: Loss = 0.7768582701683044
Epoch 5.18: Loss = 0.7679386734962463
Epoch 5.19: Loss = 0.8091229796409607
Epoch 5.20: Loss = 0.7523472905158997
Epoch 5.21: Loss = 0.7566042542457581
Epoch 5.22: Loss = 0.7764489054679871
Epoch 5.23: Loss = 0.8221389651298523
Epoch 5.24: Loss = 0.7758661508560181
Epoch 5.25: Loss = 0.7238631844520569
Epoch 5.26: Loss = 0.7970452904701233
Epoch 5.27: Loss = 0.7922080755233765
Epoch 5.28: Loss = 0.7437416911125183
Epoch 5.29: Loss = 0.758442223072052
Epoch 5.30: Loss = 0.743992030620575
	Test set:Loss: 0.794040 Acc@1: 0.715500 
Epoch 6.1: Loss = 0.7784662246704102
	Train Epoch: 6 	Loss: 0.778466 Acc@1: 0.722000 (ε = 3.22, δ = 1e-05)
Epoch 6.2: Loss = 0.8182923793792725
Epoch 6.3: Loss = 0.7192389369010925
Epoch 6.4: Loss = 0.7882965207099915
Epoch 6.5: Loss = 0.7757997512817383
Epoch 6.6: Loss = 0.7593759298324585
Epoch 6.7: Loss = 0.7388080954551697
Epoch 6.8: Loss = 0.7707163095474243
Epoch 6.9: Loss = 0.7694832682609558
Epoch 6.10: Loss = 0.7895820736885071
Epoch 6.11: Loss = 0.7677160501480103
Epoch 6.12: Loss = 0.7500597238540649
Epoch 6.13: Loss = 0.7634591460227966
Epoch 6.14: Loss = 0.7783392667770386
Epoch 6.15: Loss = 0.7944716811180115
Epoch 6.16: Loss = 0.7167969942092896
Epoch 6.17: Loss = 0.757731556892395
Epoch 6.18: Loss = 0.7488318681716919
Epoch 6.19: Loss = 0.7903523445129395
Epoch 6.20: Loss = 0.7296153903007507
Epoch 6.21: Loss = 0.7349501252174377
Epoch 6.22: Loss = 0.7549177408218384
Epoch 6.23: Loss = 0.8084607720375061
Epoch 6.24: Loss = 0.7521455883979797
Epoch 6.25: Loss = 0.705522894859314
Epoch 6.26: Loss = 0.7727869153022766
Epoch 6.27: Loss = 0.7753850817680359
Epoch 6.28: Loss = 0.7251191139221191
Epoch 6.29: Loss = 0.7408525347709656
Epoch 6.30: Loss = 0.7236513495445251
	Test set:Loss: 0.779780 Acc@1: 0.730700 
Epoch 7.1: Loss = 0.7613824605941772
	Train Epoch: 7 	Loss: 0.761382 Acc@1: 0.740000 (ε = 3.45, δ = 1e-05)
Epoch 7.2: Loss = 0.8034416437149048
Epoch 7.3: Loss = 0.7041642665863037
Epoch 7.4: Loss = 0.7750755548477173
Epoch 7.5: Loss = 0.7564728260040283
Epoch 7.6: Loss = 0.7388933300971985
Epoch 7.7: Loss = 0.7208015322685242
Epoch 7.8: Loss = 0.7565682530403137
Epoch 7.9: Loss = 0.7532321810722351
Epoch 7.10: Loss = 0.7752625346183777
Epoch 7.11: Loss = 0.7491095662117004
Epoch 7.12: Loss = 0.7380695939064026
Epoch 7.13: Loss = 0.7451376914978027
Epoch 7.14: Loss = 0.7659940719604492
Epoch 7.15: Loss = 0.7795842885971069
Epoch 7.16: Loss = 0.6995654702186584
Epoch 7.17: Loss = 0.7437323331832886
Epoch 7.18: Loss = 0.7365118265151978
Epoch 7.19: Loss = 0.7772302031517029
Epoch 7.20: Loss = 0.7144362330436707
Epoch 7.21: Loss = 0.7199437022209167
Epoch 7.22: Loss = 0.7429289817810059
Epoch 7.23: Loss = 0.7992028594017029
Epoch 7.24: Loss = 0.7380720376968384
Epoch 7.25: Loss = 0.6940141916275024
Epoch 7.26: Loss = 0.7530668377876282
Epoch 7.27: Loss = 0.7654613852500916
Epoch 7.28: Loss = 0.7143734097480774
Epoch 7.29: Loss = 0.7318820953369141
Epoch 7.30: Loss = 0.7120400667190552
	Test set:Loss: 0.770863 Acc@1: 0.739600 
Epoch 8.1: Loss = 0.7490339279174805
	Train Epoch: 8 	Loss: 0.749034 Acc@1: 0.744500 (ε = 3.66, δ = 1e-05)
Epoch 8.2: Loss = 0.7942074537277222
Epoch 8.3: Loss = 0.6956160664558411
Epoch 8.4: Loss = 0.7701966762542725
Epoch 8.5: Loss = 0.7449735403060913
Epoch 8.6: Loss = 0.727046549320221
Epoch 8.7: Loss = 0.7090835571289062
Epoch 8.8: Loss = 0.7488407492637634
Epoch 8.9: Loss = 0.7456687092781067
Epoch 8.10: Loss = 0.7680462002754211
Epoch 8.11: Loss = 0.7374089360237122
Epoch 8.12: Loss = 0.7297053933143616
Epoch 8.13: Loss = 0.7352442741394043
Epoch 8.14: Loss = 0.7554107904434204
Epoch 8.15: Loss = 0.7713393568992615
Epoch 8.16: Loss = 0.6888181567192078
Epoch 8.17: Loss = 0.7383278608322144
Epoch 8.18: Loss = 0.7293238639831543
Epoch 8.19: Loss = 0.7690435647964478
Epoch 8.20: Loss = 0.7024617195129395
Epoch 8.21: Loss = 0.7106499671936035
Epoch 8.22: Loss = 0.7345844507217407
Epoch 8.23: Loss = 0.7945219278335571
Epoch 8.24: Loss = 0.7278573513031006
Epoch 8.25: Loss = 0.685030460357666
Epoch 8.26: Loss = 0.7375256419181824
Epoch 8.27: Loss = 0.7593874335289001
Epoch 8.28: Loss = 0.7082637548446655
Epoch 8.29: Loss = 0.7274913787841797
Epoch 8.30: Loss = 0.7065269351005554
	Test set:Loss: 0.767164 Acc@1: 0.745700 
Epoch 9.1: Loss = 0.7412978410720825
	Train Epoch: 9 	Loss: 0.741298 Acc@1: 0.753500 (ε = 3.87, δ = 1e-05)
Epoch 9.2: Loss = 0.7890015244483948
Epoch 9.3: Loss = 0.6906054019927979
Epoch 9.4: Loss = 0.7651203274726868
Epoch 9.5: Loss = 0.7361986637115479
Epoch 9.6: Loss = 0.7160124182701111
Epoch 9.7: Loss = 0.7008973360061646
Epoch 9.8: Loss = 0.7438139319419861
Epoch 9.9: Loss = 0.7400294542312622
Epoch 9.10: Loss = 0.7615686058998108
Epoch 9.11: Loss = 0.7282378673553467
Epoch 9.12: Loss = 0.7249808311462402
Epoch 9.13: Loss = 0.7268221974372864
Epoch 9.14: Loss = 0.7507403492927551
Epoch 9.15: Loss = 0.7670315504074097
Epoch 9.16: Loss = 0.6774183511734009
Epoch 9.17: Loss = 0.7337120175361633
Epoch 9.18: Loss = 0.7251798510551453
Epoch 9.19: Loss = 0.760992169380188
Epoch 9.20: Loss = 0.6954490542411804
Epoch 9.21: Loss = 0.7018386125564575
Epoch 9.22: Loss = 0.7267400026321411
Epoch 9.23: Loss = 0.7902927994728088
Epoch 9.24: Loss = 0.7195773720741272
Epoch 9.25: Loss = 0.6803101301193237
Epoch 9.26: Loss = 0.7273517847061157
Epoch 9.27: Loss = 0.7527834177017212
Epoch 9.28: Loss = 0.7034575343132019
Epoch 9.29: Loss = 0.7196818590164185
Epoch 9.30: Loss = 0.7002503871917725
	Test set:Loss: 0.762722 Acc@1: 0.751900 
Epoch 10.1: Loss = 0.7331498265266418
	Train Epoch: 10 	Loss: 0.733150 Acc@1: 0.763500 (ε = 4.06, δ = 1e-05)
Epoch 10.2: Loss = 0.7846226096153259
Epoch 10.3: Loss = 0.6858104467391968
Epoch 10.4: Loss = 0.7620809674263
Epoch 10.5: Loss = 0.729719340801239
Epoch 10.6: Loss = 0.7078726291656494
Epoch 10.7: Loss = 0.6924024224281311
Epoch 10.8: Loss = 0.739557147026062
Epoch 10.9: Loss = 0.7360976338386536
Epoch 10.10: Loss = 0.7561133503913879
Epoch 10.11: Loss = 0.7206553816795349
Epoch 10.12: Loss = 0.7197549939155579
Epoch 10.13: Loss = 0.7173330187797546
Epoch 10.14: Loss = 0.7437232136726379
Epoch 10.15: Loss = 0.7604138851165771
Epoch 10.16: Loss = 0.6699074506759644
Epoch 10.17: Loss = 0.7309594750404358
Epoch 10.18: Loss = 0.720628023147583
Epoch 10.19: Loss = 0.7532442808151245
Epoch 10.20: Loss = 0.6889235377311707
Epoch 10.21: Loss = 0.696144700050354
Epoch 10.22: Loss = 0.7196365594863892
Epoch 10.23: Loss = 0.7868471741676331
Epoch 10.24: Loss = 0.7123192548751831
Epoch 10.25: Loss = 0.6766489744186401
Epoch 10.26: Loss = 0.717433512210846
Epoch 10.27: Loss = 0.7513127326965332
Epoch 10.28: Loss = 0.7004804611206055
Epoch 10.29: Loss = 0.7173516750335693
Epoch 10.30: Loss = 0.695992112159729
	Test set:Loss: 0.757950 Acc@1: 0.760100 
