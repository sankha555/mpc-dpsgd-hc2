<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>FAQ · Opacus</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="## What is Opacus?"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="FAQ · Opacus"/><meta property="og:type" content="website"/><meta property="og:url" content="https://opacus.ai/"/><meta property="og:description" content="## What is Opacus?"/><meta property="og:image" content="https://opacus.ai/img/opacus_logo.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://opacus.ai/img/opacus_logo.svg"/><link rel="shortcut icon" href="/img/opacus_favicon.svg"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-117752657-3', 'auto');
              ga('send', 'pageview');
            </script><link rel="stylesheet" href="/css/code_block_buttons.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/js/code_block_buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/js/mathjax.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/opacus_logo.svg" alt="Opacus"/></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class="siteNavGroupActive"><a href="/docs/introduction" target="_self">Introduction</a></li><li class="siteNavGroupActive siteNavItemActive"><a href="/docs/faq" target="_self">FAQ</a></li><li class=""><a href="/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/api/" target="_self">API Reference</a></li><li class=""><a href="https://github.com/pytorch/opacus" target="_self">GitHub</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>About</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">About<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/introduction">Introduction</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/docs/faq">FAQ</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer docsContainer"><div class="wrapper"><div class="post"><header class="postHeader"><a class="edit-page-link button" href="https://github.com/pytorch/opacus/tree/main/docs/faq.md" target="_blank" rel="noreferrer noopener">Edit</a><h1 id="__docusaurus" class="postHeaderTitle">FAQ</h1></header><article><div><span><h2><a class="anchor" aria-hidden="true" id="what-is-opacus"></a><a href="#what-is-opacus" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>What is Opacus?</h2>
<p>Opacus is a library that enables training PyTorch models with differential privacy. It supports training with minimal code changes required on the client, has little impact on training performance and allows the client to online track the privacy budget expended at any given moment. Please refer to <a href="https://arxiv.org/abs/2109.12298">this paper</a> to read more about Opacus.</p>
<h2><a class="anchor" aria-hidden="true" id="is-opacus-open-source-what-is-the-license"></a><a href="#is-opacus-open-source-what-is-the-license" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Is Opacus open-source? What is the license?</h2>
<p>Yes! Opacus is open-source for public use, and it is licensed under the <a href="https://github.com/pytorch/opacus/blob/main/LICENSE">Apache 2.0</a> license.</p>
<h2><a class="anchor" aria-hidden="true" id="how-can-i-report-a-bug-or-ask-a-question"></a><a href="#how-can-i-report-a-bug-or-ask-a-question" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>How can I report a bug or ask a question?</h2>
<p>You can report bugs by submitting GitHub issues. To submit a GitHub issue, please <a href="https://github.com/pytorch/opacus/issues">click here</a>.
You can ask questions in our dedicated PyTorch <a href="https://discuss.pytorch.org/c/opacus/29">Discussion Forum</a>. We actively monitor questions in the PyTorch forums with the category <code>Opacus</code>.</p>
<h2><a class="anchor" aria-hidden="true" id="id-like-to-contribute-to-opacus-how-can-i-do-that"></a><a href="#id-like-to-contribute-to-opacus-how-can-i-do-that" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>I'd like to contribute to Opacus. How can I do that?</h2>
<p>Thank you for your interest in contributing to Opacus! Submit your contributions using GitHub pull requests <a href="https://github.com/pytorch/opacus/pulls">here</a>. Please take a look at <a href="https://github.com/pytorch/opacus/blob/main/CONTRIBUTING.md">Opacus contribution guide</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="if-i-use-opacus-in-my-paper-how-can-i-cite-it"></a><a href="#if-i-use-opacus-in-my-paper-how-can-i-cite-it" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>If I use Opacus in my paper, how can I cite it?</h2>
<p>If you use Opacus in your papers, you can cite it as follows:</p>
<pre><code class="hljs">@article{opacus,
  title={Opacus: {U}ser-Friendly <span class="hljs-keyword">Differential </span>Privacy Library in {PyTorch}},
  author={Ashkan Yousefpour <span class="hljs-keyword">and </span>Igor <span class="hljs-keyword">Shilov </span><span class="hljs-keyword">and </span>Alexandre Sablayrolles <span class="hljs-keyword">and </span>Davide Testuggine <span class="hljs-keyword">and </span>Karthik Prasad <span class="hljs-keyword">and </span>Mani Malek <span class="hljs-keyword">and </span><span class="hljs-keyword">John </span>Nguyen <span class="hljs-keyword">and </span>Sayan Ghosh <span class="hljs-keyword">and </span>Akash <span class="hljs-keyword">Bharadwaj </span><span class="hljs-keyword">and </span><span class="hljs-keyword">Jessica </span>Zhao <span class="hljs-keyword">and </span>Graham Cormode <span class="hljs-keyword">and </span>Ilya Mironov},
  <span class="hljs-keyword">journal={arXiv </span>preprint arXiv:<span class="hljs-number">2109</span>.<span class="hljs-number">12298</span>},
  year={<span class="hljs-number">2021</span>}
}
</code></pre>
<h2><a class="anchor" aria-hidden="true" id="what-is-dp-sgd"></a><a href="#what-is-dp-sgd" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>What is DP-SGD?</h2>
<p>DP-SGD is an algorithm described in this <a href="https://arxiv.org/pdf/1607.00133.pdf">paper</a>; Opacus is its Pytorch implementation. Please refer to <a href="https://bit.ly/dp-sgd-algorithm-explained">this blog post</a> to read more about DP-SGD.</p>
<h2><a class="anchor" aria-hidden="true" id="how-do-i-attach-the-privacy-engine"></a><a href="#how-do-i-attach-the-privacy-engine" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>How do I attach the privacy engine?</h2>
<p>Training with Opacus is as simple as instantiating a <code>PrivacyEngine</code> and attaching it to the <code>optimizer</code>:</p>
<pre><code class="hljs css language-python"><span class="hljs-comment"># define your components as usual</span>
model = Net()
optimizer = SGD(model.parameters(), lr=<span class="hljs-number">0.05</span>)
data_loader = torch.utils.data.DataLoader(dataset, batch_size=<span class="hljs-number">1024</span>)

<span class="hljs-comment"># enter PrivacyEngine</span>
privacy_engine = PrivacyEngine()
model, optimizer, data_loader = privacy_engine.make_private(
    module=model,
    optimizer=optimizer,
    data_loader=data_loader,
    noise_multiplier=<span class="hljs-number">1.1</span>,
    max_grad_norm=<span class="hljs-number">1.0</span>,
)
<span class="hljs-comment"># Now it&#x27;s business as usual</span>
</code></pre>
<h2><a class="anchor" aria-hidden="true" id="what-is-the-secure_rng-argument-in-privacyengine"></a><a href="#what-is-the-secure_rng-argument-in-privacyengine" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>What is the secure_rng argument in PrivacyEngine?</h2>
<p>Not all pseudo random number generators (RNGs) are born equal. Most of them (including Python’s and PyTorch’s default generators, which are based on the Mersenne Twister) cannot support the quality of randomness required by cryptographic applications. The RNGs that do qualify are generally referred to as cryptographically secure RNGs, <a href="https://en.wikipedia.org/wiki/Cryptographically_secure_pseudorandom_number_generator">CSPRNGs</a>. Opacus supports a CSPRNG provided by the <a href="https://github.com/pytorch/csprng"><code>torchcsprng</code></a> library. This option is controlled by setting <code>secure_rng</code> to <code>True</code>.</p>
<p>However, using a CSPRNG comes with a large performance hit, so we normally recommend that you do your experimentation with <code>secure_rng</code> set to <code>False</code>. Once you identify a training regime that works for your application (i.e., the model’s architecture, the right hyper parameters, how long to train for, etc.), then we recommend that you turn it on and train again from scratch, so that your final model can enjoy the security this brings.</p>
<h2><a class="anchor" aria-hidden="true" id="my-model-doesnt-converge-with-default-privacy-settings-what-do-i-do"></a><a href="#my-model-doesnt-converge-with-default-privacy-settings-what-do-i-do" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>My model doesn’t converge with default privacy settings. What do I do?</h2>
<p>Opacus has several settings that control the amount of noise, which affects convergence. The most important one is <code>noise_multiplier</code>, which is typically set between 0.1 and 2. With everything else being constant, the standard deviation of the Gaussian noise is proportional to <code>noise_multiplier</code>, which means that scaling it down makes gradient computations more accurate but also less private.</p>
<p>The next parameter to adjust would be the learning rate. Compared to the non-private training, Opacus-trained models converge with a smaller learning rate (each gradient update is noisier, thus we want to take smaller steps).</p>
<p>Next one on the list is <code>max_grad_norm</code> . It sets the threshold above which Opacus clips the gradients, impairing convergence. Deeper models are less impacted by this threshold, while linear models can be badly hurt if their value is not set right.</p>
<p>If these interventions don’t help (or the model starts to converge but its privacy is wanting), it is time to take a hard look at the model architecture or its components. <a href="https://openreview.net/forum?id=rJg851rYwH">[Papernot et al. 2019]</a> can be a good starting point.</p>
<h2><a class="anchor" aria-hidden="true" id="how-to-deal-with-out-of-memory-errors"></a><a href="#how-to-deal-with-out-of-memory-errors" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>How to deal with out-of-memory errors?</h2>
<p>Dealing with per-sample gradients will inevitably put more pressure on your memory: after all, if you want to train with batch size 64, you are looking to keep 64 copies of your parameter gradients. The first sanity check to do is to make sure that you don’t go out of memory with &quot;standard&quot; training (without DP). That should guarantee that you can train with batch size of 1 at least. Then, you can check your memory usage with e.g. <code>nvidia-smi</code> as usual, gradually increasing the batch size until you find your sweet spot. Note that this may mean that you still train with small batch size, which comes with its own training behavior (i.e. higher variance between batches). Training with larger batch sizes can be beneficial, and we built <code>virtual_step</code> to make this possible while still memory efficient (see <em>what is virtual batch size</em> in these FAQs).</p>
<h2><a class="anchor" aria-hidden="true" id="what-does-epsilon11-really-mean-how-about-delta"></a><a href="#what-does-epsilon11-really-mean-how-about-delta" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>What does epsilon=1.1 really mean? How about delta?</h2>
<p>The (epsilon, delta) pair quantifies the privacy properties of the DP-SGD algorithm (see the <a href="https://bit.ly/dp-sgd-algorithm-explained">blog post</a>). A model trained with (epsilon, delta)-differential privacy (DP) protects the privacy of any training example, no matter how strange, ill-fitting, or perfect this example is.</p>
<p>Formally, (epsilon, delta)-DP statement implies that the probabilities of outputting a model <em>W</em> trained on two datasets <em>D</em> and <em>D</em>′ that differ in a single example are close:
<img src="https://raw.githubusercontent.com/pytorch/opacus/main/docs/img/epsilon-delta-dp.png" alt="epsilon-delta-dp">
This statement extends to all downstream uses of this model: its inferences, fine-tuning, distillation, etc. In other words, if the (epsilon, delta)-DP property meets your privacy objectives, releasing the entire model—its architecture, weights, activation functions—is OK privacy-wise.</p>
<p>From the expression above it is obvious that epsilon and delta play different roles: epsilon controls the multiplicative increase in the baseline probability while delta lifts all probabilities by the same amount. For instance, if your baseline scenario (the model trained on <em>D</em>′, without your data) assigns 0 probability to some event, the bound on observing this event on <em>D</em> (that includes your data) is delta. Because of that, we’d like to target epsilon to be a small constant and select delta to be tiny. A rule of thumb is to set delta to be less than the inverse of the size of the training dataset.</p>
<p>Epsilon and delta are computed <em>ex post</em>, following an optimizer run. In fact, for each delta there’s some epsilon, depending on that delta, such that the run satisfies (epsilon, delta)-DP. The call <code>privacy_engine.get_epsilon(delta=delta)</code> outputs that epsilon in its first return value.</p>
<p>Importantly, (epsilon, delta)-DP is a <em>conservative upper bound</em> on the actual privacy loss. There’s <a href="https://arxiv.org/abs/2006.07709">growing</a> <a href="https://arxiv.org/pdf/2006.11601.pdf">evidence</a> that the observable privacy loss of the DP-SGD algorithm can be significantly smaller.</p>
<h2><a class="anchor" aria-hidden="true" id="how-does-batch-size-affect-my-privacy-budget"></a><a href="#how-does-batch-size-affect-my-privacy-budget" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>How does batch size affect my privacy budget?</h2>
<p>Assuming that batches are randomly selected, an increase in the batch size increases the sampling rate, which in turn increases the privacy budget. This effect can be counterbalanced by choosing a larger learning rate (since per-batch gradients approximate the true gradient of the model better) and aborting the training earlier.</p>
<h2><a class="anchor" aria-hidden="true" id="my-model-throws-incompatiblemoduleexception-what-is-going-wrong"></a><a href="#my-model-throws-incompatiblemoduleexception-what-is-going-wrong" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>My model throws IncompatibleModuleException. What is going wrong?</h2>
<p>Your model most likely contains modules that are not compatible with Opacus. The most prominent example of these modules is batch-norm types. Before validating you model try to fix incompatible modules using <code>ModuleValidator.fix(model)</code> as described <a href="https://opacus.ai/tutorials/guide_to_module_validator#Registering-fixer">here</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="what-is-virtual-batch-size"></a><a href="#what-is-virtual-batch-size" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>What is virtual batch size?</h2>
<p>Opacus computes and stores <em>per-sample</em> gradients under the hood. What this means is that, for every regular gradient expected by the optimizer, Opacus will store <code>batch_size</code> per-sample gradients on each step. To balance peak memory requirement, which is proportional to <code>batch_size</code> ^ 2, and training performance, we use virtual batches. With virtual batches we can separate physical steps (gradient computation) and logical steps (noise addition and parameter updates): use larger batches for training, while keeping memory footprint low. See the <a href="https://opacus.ai/api/batch_memory_manager.html">Batch Memory Manager</a> for seamless integration into your training code.</p>
<h2><a class="anchor" aria-hidden="true" id="what-are-alphas"></a><a href="#what-are-alphas" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>What are <code>alphas</code>?</h2>
<p>Although we report expended privacy budget using the (epsilon, delta) language, internally, we track it using Rényi Differential Privacy (RDP) [<a href="https://arxiv.org/abs/1702.07476">Mironov 2017</a>, <a href="https://arxiv.org/abs/1908.10530">Mironov et al. 2019</a>]. In short, (alpha, epsilon)-RDP bounds the <a href="https://en.wikipedia.org/wiki/R%C3%A9nyi_entropy#R%C3%A9nyi_divergence">Rényi divergence</a> of order alpha between the distribution of the mechanism’s outputs on any two datasets that differ in a single element. An (alpha, epsilon)-RDP statement is a relaxation of epsilon-DP but retains many of its important properties that make RDP particularly well-suited for privacy analysis of DP-SGD. The <code>alphas</code> parameter instructs the privacy engine what RDP orders to use for tracking privacy expenditure.</p>
<p>When the privacy engine needs to bound the privacy loss of a training run using (epsilon, delta)-DP for a given delta, it searches for the optimal order from among <code>alphas</code>. There’s very little additional cost in expanding the list of orders. We suggest using a list <code>[1 + x / 10.0 for x in range(1, 100)] + list(range(12, 64))</code>. You can pass your own alphas by passing <code>alphas=custom_alphas</code> when calling <code>privacy_engine.make_private_with_epsilon</code>.</p>
<p>A call to <code>privacy_engine.get_epsilon(delta=delta)</code> returns a pair: an epsilon such that the training run satisfies (epsilon, delta)-DP and an optimal order alpha. An easy diagnostic to determine whether the list of <code>alphas</code> ought to be expanded is whether the returned value alpha is one of the two boundary values of <code>alphas</code>.</p>
<!-- ## How do I run Opacus in Colab?
<p>If you are getting an error like this, <code>ImportError: libcudart.so.10.2: cannot open shared object file: No such file or directory</code>, the reason is that you are on the wrong CUDA version. For example, as of October 2020 Colab is still on Cuda 10.1, while PyTorch has moved on to Cuda 10.2 as its default. You would actually see this issue even with installing PyTorch - you don't see it because PyTorch comes pre-installed in Colab, so they have the right Cuda version already.</p>
<p>The fix is to just install the package for the right Cuda version you have :)</p>
<p>Here's the copypasta to install PyTorch with CUDA 10.1:</p>
<pre><code class="hljs"><span class="hljs-attribute">pip</span> install torchcsprng==<span class="hljs-number">0</span>.<span class="hljs-number">1</span>.<span class="hljs-number">2</span>+cu<span class="hljs-number">101</span> torch==<span class="hljs-number">1</span>.<span class="hljs-number">6</span>.<span class="hljs-number">0</span>+cu<span class="hljs-number">101</span> torchvision==<span class="hljs-number">0</span>.<span class="hljs-number">7</span>.<span class="hljs-number">0</span>+cu<span class="hljs-number">101</span> -f https://download.pytorch.org/whl/torch_stable.html
</code></pre>
<p>After this, you can just <code>pip install opacus</code> and it will work :)</p>
<p>Notice our convention in naming package versions: &lt;lib_version&gt;+cu&lt;cuda_version&gt;. If at any point you lose the copypasta or forget the convention, you can simply go to the PyTorch install page, select Cuda 10.1 for Linux and you'll see it: <a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a></p>
<p>The same principle will apply for future CUDA releases should Colab and PyTorch fall out of sync again.
--&gt;</p>
</span></div></article></div><div class="docs-prevnext"><a class="docs-prev button" href="/docs/introduction"><span class="arrow-prev">← </span><span>Introduction</span></a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#what-is-opacus">What is Opacus?</a></li><li><a href="#is-opacus-open-source-what-is-the-license">Is Opacus open-source? What is the license?</a></li><li><a href="#how-can-i-report-a-bug-or-ask-a-question">How can I report a bug or ask a question?</a></li><li><a href="#id-like-to-contribute-to-opacus-how-can-i-do-that">I'd like to contribute to Opacus. How can I do that?</a></li><li><a href="#if-i-use-opacus-in-my-paper-how-can-i-cite-it">If I use Opacus in my paper, how can I cite it?</a></li><li><a href="#what-is-dp-sgd">What is DP-SGD?</a></li><li><a href="#how-do-i-attach-the-privacy-engine">How do I attach the privacy engine?</a></li><li><a href="#what-is-the-secure_rng-argument-in-privacyengine">What is the secure_rng argument in PrivacyEngine?</a></li><li><a href="#my-model-doesnt-converge-with-default-privacy-settings-what-do-i-do">My model doesn’t converge with default privacy settings. What do I do?</a></li><li><a href="#how-to-deal-with-out-of-memory-errors">How to deal with out-of-memory errors?</a></li><li><a href="#what-does-epsilon11-really-mean-how-about-delta">What does epsilon=1.1 really mean? How about delta?</a></li><li><a href="#how-does-batch-size-affect-my-privacy-budget">How does batch size affect my privacy budget?</a></li><li><a href="#my-model-throws-incompatiblemoduleexception-what-is-going-wrong">My model throws IncompatibleModuleException. What is going wrong?</a></li><li><a href="#what-is-virtual-batch-size">What is virtual batch size?</a></li><li><a href="#what-are-alphas">What are <code>alphas</code>?</a></li></ul></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/" class="nav-home"><img src="/img/opacus_favicon.svg" alt="Opacus" width="66" height="58"/></a><div class="footerSection"><h5>Docs</h5><a href="/docs/introduction">Introduction</a><a href="/docs/faq">FAQ</a><a href="/tutorials/">Tutorials</a><a href="/api/">API Reference</a></div><div class="footerSection"><h5>Github</h5><div class="social"><a class="github-button" href="https://github.com/pytorch/opacus" data-count-href="https://github.com/pytorch/opacus/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star Opacus on GitHub">opacus</a></div></div><div class="footerSection"><h5>Legal</h5><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/img/oss_logo.png" alt="Meta Open Source" width="250" height="95"/></a><section class="copyright"> Copyright © 2024 Meta Platforms, Inc.</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '207c27d819f967749142d8611de7cb19',
                indexName: 'opacus',
                inputSelector: '#search_input_react'
              });
            </script></body></html>